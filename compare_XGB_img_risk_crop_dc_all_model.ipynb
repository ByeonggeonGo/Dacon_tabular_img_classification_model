{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 13:16:16.398677: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:16.398725: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# conda install -c rapidsai -c nvidia -c conda-forge dask-cuda cudatoolkit=11.6\n",
    "# nvidia-smi\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import dask.dataframe as dd\n",
    "import dask.multiprocessing\n",
    "import dask\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "import dask_image.imread\n",
    "import dask_image.ndfilters\n",
    "import dask_image.ndmeasure\n",
    "import cv2\n",
    "from glob import glob\n",
    "import json\n",
    "import dask.array as da\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import os\n",
    "from dask import compute\n",
    "from sklearn.metrics import f1_score\n",
    "# f1_score(y_true, y_pred, average=[‘micro’, ‘macro’, ‘samples’,’weighted’ 중 하나 선택])\n",
    "import tensorflow as tf\n",
    "\n",
    "@delayed\n",
    "def padding(data, array_len, col_len):\n",
    "    pad = np.zeros((array_len, col_len))\n",
    "    length = min(array_len, len(data))\n",
    "    \n",
    "    pad[:length] = data[:length]\n",
    "    return pad\n",
    "\n",
    "@delayed\n",
    "def img_resize(img):\n",
    "    img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img = img.astype(np.float32)/255\n",
    "    return img\n",
    "\n",
    "path = os.getcwd()\n",
    "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "# # client.close()\n",
    "# cluster = LocalCluster()\n",
    "# client = Client(cluster)\n",
    "# print(cluster,client)\n",
    "# client.close()\n",
    "# http://localhost:8787/status\n",
    "\n",
    "# from dask_cuda import LocalCUDACluster\n",
    "# from dask.distributed import Client\n",
    "# client.close()\n",
    "# # http://127.0.0.1:34497/status\n",
    "# cluster = LocalCUDACluster()\n",
    "# client = Client(cluster)\n",
    "# print(cluster,client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 13:16:25.211546: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 13:16:26.904310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-27 13:16:26.904475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcubl"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6026418906247904325\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "asLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904712: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904758: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904804: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gob/miniconda3/envs/pro1/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-01-27 13:16:26.904857: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making_label_set\n",
    "\n",
    "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
    "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
    "risk = {'0':'정상','1':'초기','2':'중기','3':'말기'}\n",
    "\n",
    "\n",
    "#ensemble_labler\n",
    "label_description = {}\n",
    "for key, value in disease.items():\n",
    "    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n",
    "    for disease_code in value:\n",
    "        for risk_code in risk:\n",
    "            label = f'{key}_{disease_code}_{risk_code}'\n",
    "            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n",
    "\n",
    "global ensemble_label_encoder\n",
    "ensemble_label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
    "ensemble_label_decoder = {val:key for key, val in ensemble_label_encoder.items()}\n",
    "\n",
    "#crop_labler\n",
    "crop_label_description = {}\n",
    "for key, value in disease.items():\n",
    "    crop_label_description[f'{key}'] = f'{crop[key]}'\n",
    "    \n",
    "global crop_label_encoder\n",
    "crop_label_encoder = {key:idx for idx, key in enumerate(crop_label_description)}\n",
    "crop_label_decoder = {val:key for key, val in crop_label_encoder.items()}\n",
    "\n",
    "\n",
    "#disease_labler\n",
    "disease_label_description = {}\n",
    "for key, value in disease.items():\n",
    "    disease_label_description[f'00'] = \"정상\"\n",
    "    for disease_code,value in value.items():\n",
    "        label = f'{disease_code}'\n",
    "        disease_label_description[label] = f'{value}'\n",
    "\n",
    "global disease_label_encoder\n",
    "disease_label_encoder = {key:idx for idx, key in enumerate(disease_label_description)}\n",
    "disease_label_decoder = {val:key for key, val in disease_label_encoder.items()}\n",
    "\n",
    "\n",
    "#risk_labler\n",
    "risk_label_description = {}\n",
    "for key, value in risk.items():\n",
    "    label = f'{key}'\n",
    "    risk_label_description[label] = f'{value}'\n",
    "\n",
    "global risk_label_encoder\n",
    "risk_label_encoder = {key:idx for idx, key in enumerate(risk_label_description)}\n",
    "risk_label_decoder = {val:key for key, val in risk_label_encoder.items()}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '딸기', '2': '토마토', '3': '파프리카', '4': '오이', '5': '고추', '6': '시설포도'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_label_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': '정상', '1': '초기', '2': '중기', '3': '말기'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_label_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': '정상',\n",
       " 'a1': '딸기잿빛곰팡이병',\n",
       " 'a2': '딸기흰가루병',\n",
       " 'b1': '냉해피해',\n",
       " 'b6': '다량원소결핍 (N)',\n",
       " 'b7': '다량원소결핍 (P)',\n",
       " 'b8': '다량원소결핍 (K)',\n",
       " 'a5': '토마토흰가루병',\n",
       " 'a6': '토마토잿빛곰팡이병',\n",
       " 'b2': '열과',\n",
       " 'b3': '칼슘결핍',\n",
       " 'a9': '파프리카흰가루병',\n",
       " 'a10': '파프리카잘록병',\n",
       " 'a3': '오이노균병',\n",
       " 'a4': '오이흰가루병',\n",
       " 'a7': '고추탄저병',\n",
       " 'a8': '고추흰가루병',\n",
       " 'a11': '시설포도탄저병',\n",
       " 'a12': '시설포도노균병',\n",
       " 'b4': '일소피해',\n",
       " 'b5': '축과병'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_label_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def label_encoding(label):\n",
    "    global ensemble_label_encoder\n",
    "    encoded_label = ensemble_label_encoder[label]\n",
    "    return encoded_label\n",
    "\n",
    "@delayed\n",
    "def label_encoding_crop(label):\n",
    "    global crop_label_encoder\n",
    "    encoded_label = crop_label_encoder[label]\n",
    "    return encoded_label\n",
    "\n",
    "@delayed\n",
    "def label_encoding_disease(label):\n",
    "    global disease_label_encoder\n",
    "    encoded_label = disease_label_encoder[label]\n",
    "    return encoded_label\n",
    "\n",
    "@delayed\n",
    "def label_encoding_risk(label):\n",
    "    global risk_label_encoder\n",
    "    encoded_label = risk_label_encoder[label]\n",
    "    return encoded_label\n",
    "\n",
    "def getlable(jsonpath,type):\n",
    "    if type == \"ensemble\":\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "\n",
    "        crop = json_file['annotations']['crop']\n",
    "        disease = json_file['annotations']['disease']\n",
    "        risk = json_file['annotations']['risk']\n",
    "        label = f'{crop}_{disease}_{risk}'\n",
    "        return label\n",
    "\n",
    "    elif type == \"crop\":\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "        crop = json_file['annotations']['crop']\n",
    "        label = f'{crop}'\n",
    "        return label\n",
    "\n",
    "    elif type == \"dc\":\n",
    "        with open(jsonpath, 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "        disease = json_file['annotations']['disease']\n",
    "        label = f'{disease}'\n",
    "        return label\n",
    "\n",
    "    elif type == \"risk\":  \n",
    "        with open(jsonpath, 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "        risk = json_file['annotations']['risk']\n",
    "        label = f'{risk}'\n",
    "        return label\n",
    "\n",
    "    \n",
    "def get_label_list(labelpath_list):\n",
    "    labelarr = np.array([])\n",
    "    labelarr_crop = np.array([])\n",
    "    labelarr_dc = np.array([])\n",
    "    labelarr_risk = np.array([])\n",
    "\n",
    "\n",
    "    # labelarr = da.array([])\n",
    "    for ind,json_path in enumerate(labelpath_list):\n",
    "        # label = label_encoding(getlable(json_path))\n",
    "        # label = da.array(np.array(label_encoding(getlable(json_path))))\n",
    "        label = np.array(label_encoding(getlable(json_path,\"ensemble\")))\n",
    "        labelarr = np.append(labelarr,label)\n",
    "\n",
    "        label_crop = np.array(label_encoding_crop(getlable(json_path,\"crop\")))\n",
    "        labelarr_crop = np.append(labelarr_crop,label_crop)\n",
    "\n",
    "        label_dc = np.array(label_encoding_disease(getlable(json_path,\"dc\")))\n",
    "        labelarr_dc = np.append(labelarr_dc,label_dc)\n",
    "\n",
    "        label_risk = np.array(label_encoding_risk(getlable(json_path,\"risk\")))\n",
    "        labelarr_risk = np.append(labelarr_risk,label_risk)\n",
    "\n",
    "\n",
    "    return labelarr, labelarr_crop, labelarr_dc, labelarr_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def get_all_image(imgpath_list,image_size):\n",
    "    imgarr = np.empty((0,image_size,image_size,3), float)\n",
    "    for ind,img_path in enumerate(imgpath_list):\n",
    "        imgarr = delayed(np.append)(imgarr,img, axis = 0)\n",
    "    return imgarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.2 s, sys: 6.05 s, total: 51.3 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "@delayed\n",
    "def imageresize(img):\n",
    "    # img = dask.delayed(cv2.resize)(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "    # img = dask.delayed(img.astype(np.float32)/255)  ##픽셀값을 0~1사이로 정규화\n",
    "    # # img = np.transpose(img, (2,0,1))\n",
    "    # return dask.delayed(img.reshape)(-1,224,224,3)\n",
    "    img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img = img.astype(np.float32)/255  ##픽셀값을 0~1사이로 정규화\n",
    "    # img = np.transpose(img, (2,0,1))\n",
    "    return np.array(img)\n",
    "#making_img_set\n",
    "row_img = dask_image.imread.imread(os.path.join(path,\"data\",\"train\",\"*\",\"*.jpg\"))\n",
    "train = [imageresize(img) for img in row_img]\n",
    "train_x = np.array(dask.compute(*train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.89 s, sys: 422 ms, total: 4.32 s\n",
      "Wall time: 5.12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5767,), (5767,), (5767,), (5767,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "label_list = sorted(glob(os.path.join(path,\"data\",\"train\",\"*\",\"*.json\")))\n",
    "y_train,y_train_crop,y_train_dc,y_train_risk, = get_label_list(label_list)\n",
    "# y_train = y_train.rechunk(5767)\n",
    "results = dask.compute(*y_train)\n",
    "label = np.array(results)\n",
    "# print(label.shape)\n",
    "results_crop = dask.compute(*y_train_crop)\n",
    "label_crop = np.array(results_crop)\n",
    "#\n",
    "results_dc = dask.compute(*y_train_dc)\n",
    "label_dc = np.array(results_dc)\n",
    "#\n",
    "results_risk = dask.compute(*y_train_risk)\n",
    "label_risk = np.array(results_risk)\n",
    "label.shape,label_crop.shape,label_dc.shape,label_risk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 13:17:56.378517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-27 13:17:56.378581: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "9420800/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  \n",
    "])\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "CPU times: user 16min 6s, sys: 7min 5s, total: 23min 12s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch = 100\n",
    "data_length = len(train_x)\n",
    "loop_num = int(np.floor(data_length/batch))\n",
    "\n",
    "train_x_feature = dask.array.zeros((data_length,model(train_x[:1]).numpy().shape[1]))\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(loop_num):\n",
    "    print(i)\n",
    "    if i != loop_num-1:\n",
    "        start_p = count*batch\n",
    "        end_p = (count+1)*batch\n",
    "        train_x_feature[start_p:end_p] = model(train_x[start_p:end_p]).numpy()\n",
    "        \n",
    "    else:\n",
    "        start_p = count*batch\n",
    "        end_p = (count+1)*batch\n",
    "        train_x_feature[start_p:] = model(train_x[start_p:]).numpy()\n",
    "            \n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crop모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 조정\n",
    "y_all = label_crop\n",
    "cnn_out_dim = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(train_x_feature, y_all, test_size=0.2, shuffle= True,stratify=y_all)\n",
    "X = da.array(X).rechunk((1000,cnn_out_dim))\n",
    "X_test = da.array(X_test).rechunk((1000,cnn_out_dim))\n",
    "y = da.array(y).rechunk((1000,1))\n",
    "y_test = da.array(y_test).rechunk((1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:46253' processes=4 threads=16, memory=24.59 GiB>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:34:49] task [xgboost.dask]:tcp://127.0.0.1:40067 got new rank 0\n",
      "[13:34:49] task [xgboost.dask]:tcp://127.0.0.1:35641 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.14427\n",
      "[1]\ttrain-mlogloss:0.82625\n",
      "[2]\ttrain-mlogloss:0.61797\n",
      "[3]\ttrain-mlogloss:0.47364\n",
      "[4]\ttrain-mlogloss:0.36724\n",
      "[5]\ttrain-mlogloss:0.28829\n",
      "[6]\ttrain-mlogloss:0.22730\n",
      "[7]\ttrain-mlogloss:0.18021\n",
      "[8]\ttrain-mlogloss:0.14371\n",
      "[9]\ttrain-mlogloss:0.11582\n",
      "CPU times: user 3.44 s, sys: 1.42 s, total: 4.86 s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask.distributed import Client, LocalCluster\n",
    "if __name__ == \"__main__\":\n",
    "    with LocalCluster(dashboard_address=':3258') as cluster:\n",
    "        with Client(cluster) as client:\n",
    "            print(client)\n",
    "            # X and y must be Dask dataframes or arrays\n",
    "            \n",
    "\n",
    "            dtrain = xgb.dask.DaskDMatrix(client, X, y,)\n",
    "\n",
    "            params = {\"verbosity\": 0, \n",
    "            \"tree_method\": \"hist\", \n",
    "            \"objective\": 'multi:softmax',\n",
    "            \"num_class\":6,\n",
    "            }\n",
    "            \n",
    "            output = xgb.dask.train(\n",
    "                client,\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=10,\n",
    "                evals=[(dtrain, \"train\")],\n",
    "            )\n",
    "            y_pred = xgb.dask.predict(client, output, X_test).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155   0   4   1   1   1]\n",
      " [  1  55   4   2   1   3]\n",
      " [  0   0 415   3   2   0]\n",
      " [  0   0   8 173   0   3]\n",
      " [  0   1  38   0  87   1]\n",
      " [  1   0   4   2   0 188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.957     0.972       162\n",
      "           1      0.982     0.833     0.902        66\n",
      "           2      0.877     0.988     0.929       420\n",
      "           3      0.956     0.940     0.948       184\n",
      "           4      0.956     0.685     0.798       127\n",
      "           5      0.959     0.964     0.962       195\n",
      "\n",
      "    accuracy                          0.930      1154\n",
      "   macro avg      0.953     0.895     0.918      1154\n",
      "weighted avg      0.934     0.930     0.928      1154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>딸기_딸기잿빛곰팡이병_말기</th>\n",
       "      <th>딸기_딸기잿빛곰팡이병_정상</th>\n",
       "      <th>딸기_딸기잿빛곰팡이병_중기</th>\n",
       "      <th>딸기_딸기잿빛곰팡이병_초기</th>\n",
       "      <th>딸기_딸기흰가루병_정상</th>\n",
       "      <th>딸기_정상</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>딸기_딸기잿빛곰팡이병_말기</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>딸기_딸기잿빛곰팡이병_정상</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>딸기_딸기잿빛곰팡이병_중기</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>딸기_딸기잿빛곰팡이병_초기</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>딸기_딸기흰가루병_정상</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>딸기_정상</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds           딸기_딸기잿빛곰팡이병_말기  딸기_딸기잿빛곰팡이병_정상  딸기_딸기잿빛곰팡이병_중기  \\\n",
       "answer                                                           \n",
       "딸기_딸기잿빛곰팡이병_말기              87               1               0   \n",
       "딸기_딸기잿빛곰팡이병_정상               1              55               2   \n",
       "딸기_딸기잿빛곰팡이병_중기               0               0             173   \n",
       "딸기_딸기잿빛곰팡이병_초기               2               0               3   \n",
       "딸기_딸기흰가루병_정상                 0               0               2   \n",
       "딸기_정상                        1               0               1   \n",
       "\n",
       "preds           딸기_딸기잿빛곰팡이병_초기  딸기_딸기흰가루병_정상  딸기_정상  \n",
       "answer                                               \n",
       "딸기_딸기잿빛곰팡이병_말기              38             1      0  \n",
       "딸기_딸기잿빛곰팡이병_정상               4             3      1  \n",
       "딸기_딸기잿빛곰팡이병_중기               8             3      0  \n",
       "딸기_딸기잿빛곰팡이병_초기             415             0      0  \n",
       "딸기_딸기흰가루병_정상                 4           188      1  \n",
       "딸기_정상                        4             1    155  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = np.array([label_description[ensemble_label_decoder[int(val)]] for val in y_test])\n",
    "predss = np.array([label_description[ensemble_label_decoder[int(val)]] for val in y_pred])\n",
    "\n",
    "new_crosstab = pd.crosstab(answer, predss, rownames=['answer'], colnames=['preds'])\n",
    "new_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9184374396084466"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce43f5afc3da1ea9c2859aca36b65d9af6136ef930ed7edf27ba0e49c79ddf9d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pro1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
