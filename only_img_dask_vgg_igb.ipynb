{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalCluster(044ce8ec, 'tcp://127.0.0.1:44429', workers=4, threads=16, memory=24.59 GiB) <Client: 'tcp://127.0.0.1:44429' processes=4 threads=16, memory=24.59 GiB>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/gob/repos/Dacon_tabular_img_classification_model/dask-worker-space/worker-s268uuqx', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/gob/repos/Dacon_tabular_img_classification_model/dask-worker-space/worker-xrhjg4i1', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/gob/repos/Dacon_tabular_img_classification_model/dask-worker-space/worker-s5lloa63', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/home/gob/repos/Dacon_tabular_img_classification_model/dask-worker-space/worker-h03kdycd', purging\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.multiprocessing\n",
    "import dask\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "import dask_image.imread\n",
    "import dask_image.ndfilters\n",
    "import dask_image.ndmeasure\n",
    "import cv2\n",
    "from glob import glob\n",
    "import json\n",
    "import dask.array as da\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import os\n",
    "from dask import compute\n",
    "\n",
    "@delayed\n",
    "def padding(data, array_len, col_len):\n",
    "    pad = np.zeros((array_len, col_len))\n",
    "    length = min(array_len, len(data))\n",
    "    \n",
    "    pad[:length] = data[:length]\n",
    "    return pad\n",
    "\n",
    "@delayed\n",
    "def img_resize(img):\n",
    "    img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img = img.astype(np.float32)/255\n",
    "    return img\n",
    "\n",
    "path = os.getcwd()\n",
    "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "print(cluster,client)\n",
    "# client.close()\n",
    "# http://localhost:8787/status\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalCluster(044ce8ec, 'tcp://127.0.0.1:44429', workers=4, threads=16, memory=24.59 GiB) <Client: 'tcp://127.0.0.1:44429' processes=4 threads=16, memory=24.59 GiB>\n"
     ]
    }
   ],
   "source": [
    "print(cluster,client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13971771372354461640\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 08:46:14.988089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-21 08:46:14.988142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making_label_set\n",
    "# \n",
    "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
    "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
    "risk = {'1':'초기','2':'중기','3':'말기'}\n",
    "\n",
    "\n",
    "#ensemble_labler\n",
    "label_description = {}\n",
    "for key, value in disease.items():\n",
    "    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n",
    "    for disease_code in value:\n",
    "        for risk_code in risk:\n",
    "            label = f'{key}_{disease_code}_{risk_code}'\n",
    "            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n",
    "\n",
    "global ensemble_label_encoder\n",
    "ensemble_label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
    "ensemble_label_decoder = {val:key for key, val in ensemble_label_encoder.items()}\n",
    "\n",
    "#crop_labler\n",
    "crop_label_description = {}\n",
    "for key, value in disease.items():\n",
    "    crop_label_description[f'{key}'] = f'{crop[key]}'\n",
    "    \n",
    "global crop_label_encoder\n",
    "crop_label_encoder = {key:idx for idx, key in enumerate(crop_label_description)}\n",
    "crop_label_decoder = {val:key for key, val in crop_label_encoder.items()}\n",
    "\n",
    "\n",
    "#disease_labler\n",
    "disease_label_description = {}\n",
    "for key, value in disease.items():\n",
    "    disease_label_description[f'00'] = f'{crop[key]}'\n",
    "    for disease_code in value:\n",
    "        label = f'{disease_code}'\n",
    "        disease_label_description[label] = f'{disease_code}'\n",
    "\n",
    "global disease_label_encoder\n",
    "disease_label_encoder = {key:idx for idx, key in enumerate(disease_label_description)}\n",
    "disease_label_decoder = {val:key for key, val in disease_label_encoder.items()}\n",
    "\n",
    "\n",
    "#risk_labler\n",
    "risk_label_description = {}\n",
    "for key, value in risk.items():\n",
    "    label = f'{key}'\n",
    "    risk_label_description[label] = f'{key}'\n",
    "\n",
    "global risk_label_encoder\n",
    "risk_label_encoder = {key:idx for idx, key in enumerate(risk_label_description)}\n",
    "risk_label_decoder = {val:key for key, val in risk_label_encoder.items()}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def label_encoding(label):\n",
    "    global label_encoder\n",
    "    encoded_label = ensemble_label_encoder[label]\n",
    "    return encoded_label\n",
    "\n",
    "def getlable(jsonpath):\n",
    "    with open(jsonpath, 'r') as f:\n",
    "        json_file = json.load(f)\n",
    "\n",
    "    crop = json_file['annotations']['crop']\n",
    "    disease = json_file['annotations']['disease']\n",
    "    risk = json_file['annotations']['risk']\n",
    "    label = f'{crop}_{disease}_{risk}'\n",
    "    return label\n",
    "    \n",
    "def get_label_list(labelpath_list):\n",
    "    labelarr = np.array([])\n",
    "    # labelarr = da.array([])\n",
    "    for ind,json_path in enumerate(labelpath_list):\n",
    "        # label = label_encoding(getlable(json_path))\n",
    "        # label = da.array(np.array(label_encoding(getlable(json_path))))\n",
    "        label = np.array(label_encoding(getlable(json_path)))\n",
    "        labelarr = np.append(labelarr,label)\n",
    "    return labelarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def get_all_image(imgpath_list,image_size):\n",
    "    imgarr = np.empty((0,image_size,image_size,3), float)\n",
    "    for ind,img_path in enumerate(imgpath_list):\n",
    "        imgarr = delayed(np.append)(imgarr,img, axis = 0)\n",
    "    return imgarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making_img_set\n",
    "row_img = dask_image.imread.imread(path+\"/train/*/*.jpg\")\n",
    "# row_img = row_img.rechunk(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "model_RESNET50 = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 3.17 GiB </td>\n",
       "                        <td> 576.00 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (5767, 512, 384, 3) </td>\n",
       "                        <td> (1, 512, 384, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 17301 Tasks </td>\n",
       "                        <td> 5767 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint8 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"477\" height=\"108\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"3\" y1=\"0\" x2=\"3\" y2=\"25\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"11\" y1=\"0\" x2=\"11\" y2=\"25\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"14\" y2=\"25\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"26\" y2=\"25\" />\n",
       "  <line x1=\"29\" y1=\"0\" x2=\"29\" y2=\"25\" />\n",
       "  <line x1=\"33\" y1=\"0\" x2=\"33\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"41\" y1=\"0\" x2=\"41\" y2=\"25\" />\n",
       "  <line x1=\"44\" y1=\"0\" x2=\"44\" y2=\"25\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
       "  <line x1=\"59\" y1=\"0\" x2=\"59\" y2=\"25\" />\n",
       "  <line x1=\"63\" y1=\"0\" x2=\"63\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"71\" y1=\"0\" x2=\"71\" y2=\"25\" />\n",
       "  <line x1=\"74\" y1=\"0\" x2=\"74\" y2=\"25\" />\n",
       "  <line x1=\"78\" y1=\"0\" x2=\"78\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"86\" y1=\"0\" x2=\"86\" y2=\"25\" />\n",
       "  <line x1=\"89\" y1=\"0\" x2=\"89\" y2=\"25\" />\n",
       "  <line x1=\"93\" y1=\"0\" x2=\"93\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"101\" y1=\"0\" x2=\"101\" y2=\"25\" />\n",
       "  <line x1=\"104\" y1=\"0\" x2=\"104\" y2=\"25\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"116\" y1=\"0\" x2=\"116\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >5767</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"212\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"190\" y1=\"36\" x2=\"212\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"190\" y2=\"36\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"212\" y1=\"22\" x2=\"212\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.0,0.0 212.31022462319456,22.310224623194564 212.31022462319456,58.550773912105804 190.0,36.24054928891124\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"212\" y1=\"22\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"212\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"215\" y1=\"0\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.0,0.0 215.41261651458248,0.0 237.72284113777704,22.310224623194564 212.31022462319456,22.310224623194564\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"212\" y1=\"22\" x2=\"237\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"212\" y1=\"58\" x2=\"237\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"212\" y1=\"22\" x2=\"212\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"237\" y1=\"22\" x2=\"237\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"212.31022462319456,22.310224623194564 237.72284113777704,22.310224623194564 237.72284113777704,58.550773912105804 212.31022462319456,58.550773912105804\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"225.016533\" y=\"78.550774\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"257.722841\" y=\"40.430499\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,257.722841,40.430499)\">384</text>\n",
       "  <text x=\"191.155112\" y=\"67.395662\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,191.155112,67.395662)\">512</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<_map_read_frame, shape=(5767, 512, 384, 3), dtype=uint8, chunksize=(1, 512, 384, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def imageresize(img):\n",
    "    # img = dask.delayed(cv2.resize)(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "    # img = dask.delayed(img.astype(np.float32)/255)  ##픽셀값을 0~1사이로 정규화\n",
    "    # # img = np.transpose(img, (2,0,1))\n",
    "    # return dask.delayed(img.reshape)(-1,224,224,3)\n",
    "    img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img = img.astype(np.float32)/255  ##픽셀값을 0~1사이로 정규화\n",
    "    # img = np.transpose(img, (2,0,1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [imageresize(img) for img in row_img]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "minibatch_size = 200\n",
    "data_length = len(test)\n",
    "loop_num = int(np.floor(data_length/minibatch_size))\n",
    "train_x = np.zeros((data_length,1000))\n",
    "\n",
    "count = 0\n",
    "for i in range(loop_num):\n",
    "    print(i)\n",
    "    if i != loop_num-1:\n",
    "        start_p = count*minibatch_size\n",
    "        end_p = (count+1)*minibatch_size\n",
    "        train_x[start_p:end_p] = model_RESNET50(np.array(compute(test[start_p:end_p])[0]))\n",
    "        \n",
    "    else:\n",
    "        start_p = count*minibatch_size\n",
    "        end_p = (count+1)*minibatch_size\n",
    "        train_x[start_p:] = model_RESNET50(np.array(compute(test[start_p:])[0]))\n",
    "            \n",
    "    count += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5767, 1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = sorted(glob(path+\"/train/*/*.json\"))\n",
    "y_train = get_label_list(label_list)\n",
    "# y_train = y_train.rechunk(5767)\n",
    "results = dask.compute(*y_train)\n",
    "label = np.array(results)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gob/anaconda3/envs/dacon_parm_01/lib/python3.7/site-packages/xgboost/core.py:502: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  format(\", \".join(args_msg)), FutureWarning\n",
      "/home/gob/anaconda3/envs/dacon_parm_01/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.46835899353027\n"
     ]
    }
   ],
   "source": [
    "params = {\"tree_method\": \"gpu_hist\", \n",
    "          \"objective\": 'multi:softmax',\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.8,\n",
    "        #   \"single_precision_histogram\" : True,\n",
    "          }\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "xgb_model = xgb.XGBClassifier(params,eval_metric='mlogloss',).fit(train_x,label)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making_img_set\n",
    "test_row_img = dask_image.imread.imread(path+\"/test/*/*.jpg\")\n",
    "# test_row_img = test_row_img.rechunk(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "0\n",
      "01010\n",
      "here\n",
      "1\n",
      "01010\n",
      "here\n",
      "2\n",
      "01010\n",
      "here\n",
      "3\n",
      "01010\n",
      "here\n",
      "4\n",
      "01010\n",
      "here\n",
      "5\n",
      "01010\n",
      "here\n",
      "6\n",
      "01010\n"
     ]
    }
   ],
   "source": [
    "batch = [imageresize(img) for img in test_row_img[:]]\n",
    "print(\"ok\")\n",
    "minibatch_size = 100\n",
    "data_length = len(batch)\n",
    "loop_num = int(np.floor(data_length/minibatch_size))\n",
    "# input_x = np.zeros((data_length,1000))\n",
    "input_x = dask.array.zeros((data_length,1000))\n",
    "\n",
    "count = 0\n",
    "for i in range(loop_num):\n",
    "    print(i)\n",
    "    if i != loop_num-1:\n",
    "        start_p = count*minibatch_size\n",
    "        end_p = (count+1)*minibatch_size\n",
    "        print(\"01010\")\n",
    "        input_x[start_p:end_p] = model_RESNET50(np.array(compute(batch[start_p:end_p])[0])).numpy()\n",
    "        \n",
    "    else:\n",
    "        start_p = count*minibatch_size\n",
    "        end_p = (count+1)*minibatch_size\n",
    "        print(\"here\")\n",
    "        input_x[start_p:] = model_RESNET50(np.array(compute(batch[start_p:])[0])).numpy()\n",
    "        print(\"here\")\n",
    "    count += 1\n",
    "    print(\"here\")\n",
    "\n",
    "out = xgb_model.predict(input_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/submissions/gogo_submission_05.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_302/1190143431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mensemble_label_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/submissions/gogo_submission_05.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dacon_parm_01/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3482\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3483\u001b[0m         )\n\u001b[1;32m   3484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dacon_parm_01/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dacon_parm_01/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         ) as handles:\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dacon_parm_01/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/submissions/gogo_submission_05.csv'"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(path+\"/sample_submission.csv\")\n",
    "submission.loc[:,'label'] = np.array([ensemble_label_decoder[int(val)] for val in out])\n",
    "submission.to_csv(path+'/submissions/gogo_submission_05.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
